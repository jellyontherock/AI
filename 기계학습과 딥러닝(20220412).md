# 기계학습과 딥러닝

1. 정리
    1. 전반적인 내용에 대해서 살펴보기 위함.
    2. NLP(자연어 처리 기술)에 관심이 있어 관련한 자료를 추가할 예정이다.
    3. 인공지능 기술 분류
        
        ![Untitled](https://user-images.githubusercontent.com/99526042/162776735-4cdfa864-2903-4138-af65-0c84a8027aba.png)
        

1. 기계학습의 분류
    
    ![Untitled 1](https://user-images.githubusercontent.com/99526042/162776682-4f3dc306-be9e-4872-858a-61681e5c474c.png)
    
    1. 지도 학습
        - 분류(Classification)
            
            ![Untitled 2](https://user-images.githubusercontent.com/99526042/162776696-cb4da8ae-59a9-4da9-a71d-3959206a0c42.png)
            
        - 회귀(Regression)
            - 분류와 마찬가지로 지도학습의 한 분야. 주어진 입력에 대하여 연속적인 숫자를 예측. (분류에 사용되는 알고리즘 사용 가능 - 나이브 베이즈 제외)
    2. 비지도 학습
        - 군집화(Clustering)
            - 비지도 학습의 한 분야
            - 비슷한 데이터들을 사전에 정의되지 않은 그룹으로 묶은 것.
        - 차원 축소(Dimensionality Reduction)
            - 일반적으로 원래 데이터의 차원보다 더 작은 차원으로 축소하여 사람이나, 머신러닝 알고리즘이 보다 쉽게 해석할 수 있도록 하는 작업.
            - 주요 알고리즘 → PCA, t-SNE, NMF
    3. 강화 학습 (Reinforcement Learning)
        1. 학습의 주체가 되는 에이전트가 주어진 환경에 대해 어떻게 행동해야 하는지를 학습하기 위한 방법론.
        2. 입력, 출력을 쌍으로 이루어진 훈련 집합을 **사용하지 않는다.** (지도학습과 차이)
        3. 최근에는 딥러닝에 기반한 DQN(Deep Q-Network) 등을 통해 주목받음.

1. 기계학습 성능평가 데이터 셋 & 성능지표
    
    ![Untitled 3](https://user-images.githubusercontent.com/99526042/162776701-41ecc127-5144-45fa-9dcb-376e294ff25d.png)
    
    ![Untitled 4](https://user-images.githubusercontent.com/99526042/162776709-0191d232-ebfa-40bb-aa99-ad85c8ee8ec7.png)
    

1. 딥러닝 기반 자연어 처리의 주요 분야
    1. 언어 모델
    2. 문서 분류
    3. 문서 생성
    4. 문서 요약
    5. 질의 응답
    6. 기계 번역

1. 자연어 처리 주요 딥러닝 기법
    1. RNN (Recurrent Neural Networks ; 순환 신경망)
        1. 주어진 입력값들의 순서가 의미가 있을 때 사용되는 신경망
        2. 시계열 값의 분석 등
        3. 단어들의 순서에 의해 문맥이 결정되기 때문에 문맥 파악을 위해서 사용.
        4. 양방향으로 층을 쌓아 구현하는 LSTM 연구도 있음.
        5. 딥러닝의 기울기 소실 문제
            1. RNN은 긴 문장에서는 앞 부분의 정보가 사라지는 결과 나타남
            2. LSTM(Long Short-Term Memory)은 이를 보완하기 위한 모형
                1. RNN 은닉 상태의 값에 셀 상태값 추가 → 장기 기억에 약한 점 보완
            3. GRU(Gated Recurrent Unit) 
                1. LSTM의 변형으로, 그의 계산량이 많아 학습에 시간이 많이 걸리는 것을 보완
        
        ![Untitled 5](https://user-images.githubusercontent.com/99526042/162776713-ec783ca7-9ec8-45a9-b029-f307be7a1f2c.png)
        
    2. CNN (Convolutional Neural Networks; 합성곱 신경망)
        1. 원래 이미지 처리(이미지의 주변 정보 학습)를 위해 개발된 신경망
        2. 자연어 처리에서도 뛰어난 성능을 보여, 그 활용 분야가 넓어지게 됨.
        3. 구성
            1. 합성곱층(convolution layer)
                1. 2차원 이미지에서 특정 영역의 특징을 추출하는 역할을 하는데, 이는 연속된 단어들의 특징을 추출하는 것과 유사한 특성.
            2. 풀링층(pooling)
        
        ![Untitled 6](https://user-images.githubusercontent.com/99526042/162776720-50c8ba45-6833-4e9b-b049-34f771f1cf40.png)
        

c.  시퀀스-투-시퀀스 모형 (Sequence-to-Sequence)

    [점프 투 파이썬](https://wikidocs.net/24996)

d. 어텐션 메커니즘 (Attention Mechanism)

e. 트랜스포머 (Transformer)

f. GPT (Generative Pre-Trained Transformer)

1. 트랜스포머에 기반한 모형

g. BERT(Bidirectional Encoder Representations from Transformer)

1. 트랜스포머 구조에 기반한 모형

1. 자연어 처리 성능 평가를 위한 데이터셋 및 평가 지표
    
    ![Untitled 7](https://user-images.githubusercontent.com/99526042/162776725-89f04c31-9f72-4137-8ef0-a777dfc2a44e.png)
    

    ![Untitled 8](https://user-images.githubusercontent.com/99526042/162776729-bd0bb2df-49b3-451f-8484-eaedbec2a41e.png)

참고문헌

1. [딥러닝 중심의 자연어 처리 기술 현황 분석Analysis of the Status of Natural Language Processing Technology Based on Deep Learning](https://library.kyonggi.ac.kr/eds/detail/edskis_edskis.3904221) *[한국빅데이터학회지 / The Korean Journal of BigData*. Aug 31, 2021 6(1):63](https://library.kyonggi.ac.kr/eds/brief/discoveryResult?st=KWRD&service_type=brief&si=SO&q=%3Ci%3E%ED%95%9C%EA%B5%AD%EB%B9%85%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%95%99%ED%9A%8C%EC%A7%80%20/%20The%20Korean%20Journal%20of%20BigData%3C/i%3E.%20Aug%2031,%202021%206(1):63) [박상언 / Park Sang-un](https://library.kyonggi.ac.kr/eds/brief/discoveryResult?st=KWRD&service_type=brief&si=AU&q=%22%EB%B0%95%EC%83%81%EC%96%B8%22)

[https://www.koreascience.or.kr/article/JAKO202130053222371.pdf](https://www.koreascience.or.kr/article/JAKO202130053222371.pdf)


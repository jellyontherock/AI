# 12일차

# 1. Fashion Mnist

![다운로드.png](12%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%8E%E1%85%A1%20db304/%EB%8B%A4%EC%9A%B4%EB%A1%9C%EB%93%9C.png)

```python
# 전체 예제

import tensorflow as tf 
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import mnist
from tensorflow.python.keras.utils.vis_utils import plot_model

# 1. Fashion MNIST 데이터셋 임포트
fashion_mnist = tf.keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

from sklearn.model_selection import StratifiedShuffleSplit    
split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=1004)

for train, cv in split.split(train_images,train_labels):
  X_train=train_images[train]
  X_cv=train_images[cv]
  y_train=train_labels[train]
  y_cv=train_labels[cv]
  
print(sum(y_train==1)==sum(y_cv==1)*4)

#https://reminder-by-kwan.tistory.com/118

# 2. 데이터 전처리
train_images, test_images = train_images / 255.0, test_images / 255.0

# 3. 모델 구성
model = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])

# 4. 모델 컴파일
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'],
              )

# 5. 모델 훈련
history = model.fit(train_images, train_labels, epochs=5, validation_data=(X_cv, y_cv))

# 6. 정확도 평가하기
loss, accuracy = model.evaluate(test_images, test_labels)
print(loss, accuracy)

# 7. 예측하기
predictions = model.predict(test_images)
print(predictions[0]) 
print(np.argmax(predictions[0]))
```

```python
# 1. 테스트 plot으로 랜덤 평가

p_test = model.predict(test_images).argmax(axis = 1)
miss_id = np.where(p_test != test_labels)[0]

i = np.random.choice(miss_id)
plt.imshow(test_images[i])
plt.title(f"true:{test_labels[i]}, predict:{p_test[i]}")

# 2. 테스트 셋으로 모델 평가
score = model.evaluate(test_images, test_labels, verbose=0)
print('\n', 'Test accuracy:', score[1])

# 3. loss, val_loss로 오버슈팅 등 평가
import pandas as pd
history_frame = pd.DataFrame(history.history)
history_frame.loc[:, ['loss', 'val_loss']].plot()
history_frame.loc[:, ['accuracy', 'val_accuracy']].plot();
```

[20220331.ipynb](https://colab.research.google.com/drive/1M81ye0Ob2kbk64vYN_6ZENXxvDGfyHNj)

# 2. Keras 용어 정리

### tf.keras.layers.Conv2D

- [https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)
    
    > `input_shape`
     (tuple of integers or `None`
    , does not include the sample axis), e.g. `input_shape=(128, 128, 3)`
     for **128x128 RGB pictures**
    > 
    
    ```python
    tf.keras.layers.Conv2D(
        filters,
        kernel_size,
        strides=(1, 1),
        padding='valid',
        data_format=None,
        dilation_rate=(1, 1),
        groups=1,
        activation=None,
        use_bias=True,
        kernel_initializer='glorot_uniform',
        bias_initializer='zeros',
        kernel_regularizer=None,
        bias_regularizer=None,
        activity_regularizer=None,
        kernel_constraint=None,
        bias_constraint=None,
        **kwargs
    )
    ```
    

## tf.keras.layers.MaxPooling2D

- [https://www.tensorflow.org/api_docs/python/tf/compat/v1/layers/MaxPooling2D](https://www.tensorflow.org/api_docs/python/tf/compat/v1/layers/MaxPooling2D)
    
    [https://supermemi.tistory.com/16](https://supermemi.tistory.com/16)
    
    ![Untitled](12%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%8E%E1%85%A1%20db304/Untitled.png)
    
    ![Untitled](12%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%8E%E1%85%A1%20db304/Untitled%201.png)
    
    ![Untitled](12%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%8E%E1%85%A1%20db304/Untitled%202.png)
    
    1. Max Pooling : 정해진 크기 안에서 가장 큰 값만 뽑아낸다.
    
    2. Average Pooling : 정해진 크기 안의 값들의 평균을 뽑아낸다.
    
    ![Untitled](12%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%8E%E1%85%A1%20db304/Untitled%203.png)
    
    ```python
    tf.compat.v1.layers.MaxPooling2D(
        pool_size,
        strides,
        padding='valid',
        data_format='channels_last',
        name=None,
        **kwargs
    )
    ```
    

## tf.keras.layers.Flatten

- [https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten)
    
    입력을 평평하게 한다. 배치 사이즈에는 영향을 미치지 않는다.
    
    ```python
    tf.keras.layers.Flatten(
        data_format=None, **kwargs
    )
    ```
    

## tf.keras.layers.Dense

- [https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)
    
    [https://sevillabk.github.io/Dense/](https://sevillabk.github.io/Dense/)
    
    조밀하게 연결된 일반 NN 레이어 입니다.
    
    ```python
    tf.keras.layers.Dense(
        units,
        activation=None,
        use_bias=True,
        kernel_initializer='glorot_uniform',
        bias_initializer='zeros',
        kernel_regularizer=None,
        bias_regularizer=None,
        activity_regularizer=None,
        kernel_constraint=None,
        bias_constraint=None,
        **kwargs
    )
    ```
    
    ```python
    Dense의 주요 인자들은 아래와 같습니다.
    
    첫번째 인자(units): 출력 뉴런의 수를 설정합니다.
    **input_dim** : 입력 뉴련의 수를 설정합니다.
    **kernel_initializer** : 가중치를 초기화하는 방법을 설정합니다.
    		uniform : 균일 분포
    		normal : 가우시안 분포
    **activation** : 활성화함수를 설정합니다.
    		linear : 디폴트 값으로 입력값과 가중치로 계산된 결과 값이 그대로 출력으로 나옵니다
    		sigmoid : 시그모이드 함수로 이진분류에서 출력층에 주로 쓰입니다
    		softmax : 소프드맥스 함수로 다중클래스 분류문제에서 출력층에 주로 쓰입니다.
    		relu: Rectified Linear Unit 함수로 은닉층에서 주로 쓰입니다.
    ```
    

## model.summary()

- 예시 (출력값)
    
    ```markdown
    Model: "model"
    __________________________________________________________________________________________________
     Layer (type)                   Output Shape         Param #     Connected to                     
    ==================================================================================================
     input (InputLayer)             [(None, 28, 28, 1)]  0           []                               
                                                                                                      
     conv_1 (Conv2D)                (None, 26, 26, 64)   640         ['input[0][0]']                  
                                                                                                      
     maxpool_1 (MaxPooling2D)       (None, 13, 13, 64)   0           ['conv_1[0][0]']                 
                                                                                                      
     conv_2 (Conv2D)                (None, 11, 11, 128)  73856       ['maxpool_1[0][0]']              
                                                                                                      
     maxpool_2 (MaxPooling2D)       (None, 5, 5, 128)    0           ['conv_2[0][0]']                 
                                                                                                      
     flatten_1 (Flatten)            (None, 3200)         0           ['maxpool_2[0][0]']              
                                                                                                      
     flatten_2 (Flatten)            (None, 784)          0           ['input[0][0]']                  
                                                                                                      
     concatenate (Concatenate)      (None, 3984)         0           ['flatten_1[0][0]',              
                                                                      'flatten_2[0][0]']              
                                                                                                      
     num_out (Dense)                (None, 10)           39850       ['concatenate[0][0]']            
                                                                                                      
     odd_out (Dense)                (None, 1)            785         ['flatten_2[0][0]']              
                                                                                                      
    ==================================================================================================
    Total params: 115,131
    Trainable params: 115,131
    Non-trainable params: 0
    __________________________________________________________________________________________________
    ```
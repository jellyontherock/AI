# 19일차

## 1. 수업 내용

- 지도 학습과 비지도 학습
    - 
    
    [day20-1비지도_학습.pdf의 사본](https://drive.google.com/file/d/1xvWBYJhY_jRaaJCH8K5zC8JAQSfHAoO9/view?usp=drivesdk)
    
- 차원 축소
    - 
    
    [day20-2차원축소.pdf의 사본](https://drive.google.com/file/d/1_T2XQXXWhG5ITGWMjRKFEOjXJ4MSieAC/view?usp=drivesdk)
    
- Manifold Learning
    - 
    
    [day20-3Manifold_Learning.pdf의 사본](https://drive.google.com/file/d/1QQ80fQ6VbOkws92f0m6Zynvn9wyLq2xJ/view?usp=drivesdk)
    
- AE (Auto Encoder)
    - 
    
    [day20-4AE.pdf의 사본](https://drive.google.com/file/d/1EG6gnJ615wXDBUn5nm9vTpU_c6bemGMO/view?usp=drivesdk)
    

## 2. 스터디 내용

- 백준 단계별로 풀기 - 기초수학 2 풀이
- 다음주에는 ‘재귀’ 풀이 발표 예정
    - 
    
    [재귀](https://www.acmicpc.net/step/19)
    
- 각자 진로 고민 얘기 ( → 일단 열심히 하자(?))
    - 금융 IT  vs 딥러닝, 머신러닝 분야?
- 기초수학 2에서 소수 구하기에 대한 논의
- 에라토스테네스의 채에 대해
    - 프로그래밍 언어로 구현 할 때에 ⇒ 루트 값까지만 구하면 충분하다.

[](https://ko.wikipedia.org/wiki/%EC%97%90%EB%9D%BC%ED%86%A0%EC%8A%A4%ED%85%8C%EB%84%A4%EC%8A%A4%EC%9D%98_%EC%B2%B4)

- 느낀점 : 수학에 대한 이해가 있어야 접근하기 쉬운 문제들이 있는 것 같다. 아예 무지한 경우에는... 이번처럼 당혹스러운 경우도 생김.

## 3. 셀프 Q&A

1. 오늘 수업 내용을 3줄 요약해보세요. ⇒ Auto Encoder을 설명하기 위한 기반이 됩니다.
    1. 비지도 학습은 패턴을 알 수 없거나 다루기 어려운 문제를 해결하는 데 도움이 된다.
    2. 차원 축소하는 방법은 2가지이다. 
        1. Feature Selection(기존 변수들 중 상관관계가 존재하는 변수 추출)
        2. Feature Extraciton(기존의 변수를 변환해 새로운 변수 추출)
    3. Mainfold Learning ⇒ 데이터 차원을 축소하기 위해 실행합니다.
        1. 차원 축소의 결과를 직관적으로 보여줍니다.
        
        ![Untitled](https://user-images.githubusercontent.com/99526042/162744189-bd4432c8-85e0-4e7c-8068-4b7dc181e4f4.png)        
    
2. 어쨌든 AE가 뭡니까?
    1. 압축된 표현이 원래의 데이터를 대표할 수 있도록 학습하는 것입니다. 압축된 저차원의 데이터를 통해서 다시 새로운 데이터로 복구할 수 있을까? 에 초점이 맞춰져있습니다.
    2. 데이터의 노이즈(중요 요소가 아닌 것)를 어떻게 제거하는지 학습하는 것을 통해, 차원을 줄이는 것입니다.
    3. 입력 → encoding → 차원 축소(=압축) → decoding → 출력 과정이 있습니다.
    4. 손실이 적으면 당연히 좋겠죠?
        1. 
        
        ![Untitled 1](https://user-images.githubusercontent.com/99526042/162744211-799f4d4e-9efe-425b-9913-5b7f80f4f616.png)

        
        입력과 Encoding → Decoding 된 결과에 차이에 대한 평균이 0 에 까까워 지도록 설
        계하면 된다, 고 합니다.
        
    5. 구성
        1. Encoder
        2. Decoder 
    
    1. 과소 완전 AE는 뭡니까?
        1. 아래 그림처럼 input layer과 output layer 보다 hidden layer가 중요 요소들만을 가진채 그 개수가 적은 상태를 말합니다. 
            
          ![Untitled 2](https://user-images.githubusercontent.com/99526042/162744214-af392119-7ea3-4f12-bb51-e612bb9a72ba.png)
            
        
    2. AE의 종류에 대해서
        1. 과소 완전 AE (Undercomplete Autoencoder)
        2. Stackede Autoencoder (적층 AE 혹은 Deep AE)
        3. Sparse Autoencoders
            1. A sparse autoencoder is simply an autoencoder whose training criterion involves a **sparsity penalty.**
                
                ⇒ 희소성 패널티를 주어서 학습하는 것.
                
                ⇒ 패널티의 방식은 (1) L1 regularization (2) KL-divergence가 있다.
                
                    ![Untitled 3](https://user-images.githubusercontent.com/99526042/162744218-d54e0eac-ad4e-4c17-918f-09b629771905.png)
                
            2. simple Autoencoder과 비교했을때, loss값이 더 적게 나온다. 따라서, 일반 AE 보다 더 나은 성능을 발휘한다.
                
                ![Untitled 4](https://user-images.githubusercontent.com/99526042/162744222-90296fa1-9c9a-487c-b146-d4bed02c7463.png)
                
        4. Denoising Autoencoders
            1. 이 그림만 봐도 느껴진다. denoising!!
            
                ![Untitled 5](https://user-images.githubusercontent.com/99526042/162744223-fff58675-e9f7-496f-9eb9-79ea73a81e92.png)
            
            1. Image Denoising
                1. Denoising or noise reduction is the process of removing noise from a signal. This can be an image, audio or a document. You can train an Autoencoder network to learn how to remove noise from pictures. (이미지, 문서, 음성 등에서도 사용할 수 있다!)
                    
                ![Untitled 6](https://user-images.githubusercontent.com/99526042/162744226-cd31636e-6ffb-40e4-b542-bf9c2ed38796.png)
                    

1. Tensorflow 예시
    1. 
    
    [Autoencoder 소개 | TensorFlow Core](https://www.tensorflow.org/tutorials/generative/autoencoder?hl=ko)
    

## 5. 참고 문헌

멀티캠퍼스 수업자료

[오토인코더 (Autoencoder)](https://www.notion.so/Autoencoder-e0a65b4cd2454e47a75c540b425455ad) 

[What happens in sparse autencoder](https://medium.com/@syoya/what-happens-in-sparse-autencoder-b9a5a69da5c6)

[Auto-Encoder: What Is It? And What Is It Used For? (Part 1)](https://towardsdatascience.com/auto-encoder-what-is-it-and-what-is-it-used-for-part-1-3e5c6f017726)

[Denoising autoencoders with Keras, TensorFlow, and Deep Learning - PyImageSearch](https://pyimagesearch.com/2020/02/24/denoising-autoencoders-with-keras-tensorflow-and-deep-learning/)

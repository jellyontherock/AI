# 1일차

## 1. 수업 내용

- 강사님은 서울대이며 하버드에서 adviser였다. 이왜진
- 선형 회귀분석
    - 종속변수가 연속형 변수 일 때
    - 온도, 키, 몸무게, 나이
- 로지스틱 회귀분석
    - 범주형 변수 일 때
        - 성별, 혈액형, 성적
    - sigmoid (0~1로 때려박아주는 function이다)
    - y ⇒ 0~1
    - 선형 회귀분석에 sigmoid 한 것.
    - ROC Curve의 면적, **AUC가 높으면 성능 좋은 것**.
    - threshold or cut off를 높이거나 낮춰야 하는 문제.
    - accuracy는 쓰레기.
    - sensitivity or specificity가 중요 (아산병원 vs 동네병원)
    
    ![Untitled](https://user-images.githubusercontent.com/99526042/163565917-bddd9781-2911-486f-abfc-9c8bd6753f34.png)
    
- 정규화
    - loss function 커스텀 가능
    - 이거 해석하고 쓸 줄 알면 고수

## 2. 정리

1. 오즈비 뭐냐 ⇒ odds ratio
    1. log(odds) = ax+b 일때 odds = exp(ax+b)
    2. e^a ⇒ odds이다 강사님이 뭐뭐뭐뭐 신기하죠?라고 하심.
    3. odds = 성공확률 / 실패확률 ( P / (1-P) )
    4. odds 두 개의 비율. 그것이 오즈비다. 여기서는 이렇게 쓴다.
    
    ```python
    pd.DataFrame({
        'Coefficient': Model.params,
        **'OddsRatio': np.exp(Model.params),**
        'P-value': Model.pvalues
    })
    ```
    

[상대위험도(Relative Risk) vs 오즈비(Odds Ratio)](https://bioinformaticsandme.tistory.com/287)

1. 정확도만이 높다고 좋은 모델은 아니다라는 말 이해해라
    1. 정확도는 쓰레기이며 (물론 중요할 때도.)
    2. sensitivity or specificity 를 상황에 따라서 봐라.
2. 선형 회귀분석에서 손실함수와 최소제곱법
    1. 손실함수
        
        ![Untitled 1](https://user-images.githubusercontent.com/99526042/163565832-4f7a51fb-b5bc-432c-b6a6-6fc243555074.png)

        
    2. 최소제곱법
        1. Error의 제곱 값이 최소가 되는 선형 방정식을 구한다.
3. 종속변수에 대한 coefficient 개념 뭐냐
    1. y = ax+b에서 a를 담당합니다.
    2. 기울기입니다.
    3. x가 1 증가하면 y는 a배 증가합니다.

## 3. 실습

1. Linear Regression
    1. dataframe과 matrics의 차이
        
        # vector, matrics 모두 같은 format이어야 한다.
        # list는 다 넣음 (str, numerics, list 등)
        # dataframe은 컬럼별로 다른 format이 들어갈 수 있다.
        
    2. const에 대한 내용
        
        ```python
        import statsmodels.api as sm
        
        InputFeature = Data['Temp']
        InputFeature = sm.add_constant(InputFeature)
        
        print(InputFeature.head()) #const는 y=ax+b에서 b임. temp는 x
        
        const       Temp
        0    1.0  35.292157
        1    1.0  31.200472
        2    1.0  32.936214
        3    1.0  36.722680
        4    1.0  35.602674
        ```
        
    3. 결론
        
        ```markdown
        모델의 해석
        Coef: 모델의 기울기. Coefficient of Temp: 1.3059
        기온이 1도 오를 때, 아이스아메리카노는 1.3059잔 더 팔린다.
        
        Pvalue (P>|t|): < 0.05 보다 작음
        -> 유의하게 Coefficient가 0이 아니다.
        즉 기온이 아메리카노에 영향을 준다.
        ```
        

1. Logistic Regression
    - model 생성
        
        ```python
        InputFeature = sm.add_constant(InputFeature)
        model = sm.Logit(Label, InputFeature)
        
        # model = sm.OLS( lnodds(Label), lnodds(InputFeature)) 둘다 쓸 수 있음
        # R <= gim(Label  - X1 + X2, data = df) <= linear model <= sigmoid 씌우면 같음
        ```
        
    - coefficient 보고 a>0, a<0 이면 p-value 확인
    - 0.025를 보고 0, 음수값을 포함하는지 안하는지 확인.  (쓸만하다 아니다 판단하기도)
        
        ```python
        Logit Regression Results                           
        ==============================================================================
        Dep. Variable:          special_sales   No. Observations:                   21
        Model:                          Logit   Df Residuals:                       18
        Method:                           MLE   Df Model:                            2
        Date:                Fri, 15 Apr 2022   Pseudo R-squ.:                  0.3622
        Time:                        06:21:51   Log-Likelihood:                -8.9010
        converged:                       True   LL-Null:                       -13.955
        Covariance Type:            nonrobust   LLR p-value:                  0.006383
        ====================================================================================
                               coef    std err          z      P>|z|      [0.025      0.975]
        ------------------------------------------------------------------------------------
        const              -15.2035      7.657     -1.986      0.047     -30.210      -0.197
        busy_day             2.4426      1.240      1.969      0.049       0.011       4.874
        high_temperature     0.5445      0.297      1.834      0.067      -0.037       1.126
        ====================================================================================
        ```
        
    - 해석하기
        - Coefficient: ln ( odds ) = 2.4426 * busy_day + 0.5545 * high_temperature + const
        - odds를 알기 위해서는 exponential을 해주어야한다. (log 없애기)
        
        ```python
        np.exp(model.params).round(4)
        
        const                0.0000
        busy_day            11.5035
        high_temperature     1.7238
        dtype: float64
        ```
        
    - p-value
        - busy_day는 0.05보다 작음, 즉 coef가 0보다 크다는 뜻. 유의한 변수
        - High temperature는 p-value가 0.067로 근소하게 유의하지 않음.
        - 하지만 ***0.1보다 작기에 이를 border라고도 표현함***
        - 비록 유의하지는 않지만, 어느정도 영향이 있을 것으로 짐작 가능
    
    1. Lung Cancer
        1. Logistic regression을 활용하여, 폐암 환자의 재발을 예측하는 연구를 각자 진행해볼거에요. 다만, ***예측은 하되, 모델을 꼭 해석할 수 있어야 합니다.***
            1. Logistic regression 모델을 Train 데이터에 학습한다.
            2. 변수에서 중요한 변수들에 대해서 설명하고, Odds ratio를 구한다.
            3. 필요없는 변수를 제외한 Feature를 구성한다.
            4. 최종 모델을 만든다.
            5. Validation data에 적용하여 예측한다.
        2. 해당 예제에 대한 내용 정리
            1. 강사님 코드 보면서 느끼는 점... 볼 수록 새롭다.
            
            ```python
            os.chdir('경로')
            os.listdir()
            
            ['.ipynb_checkpoints',
             '01.LinearRegression.ipynb',
             '02.LogisticRegression.ipynb',
             'Train.csv',
             'Valid.csv']
            
            df = pd.read_csv('Train.csv')
            print(df.head())
            ```
            
            b.  이렇게 하면 바로 불러오기 가능
            
            c.  코드 너무 고급져
            
            ```python
            Vari, Coef, Pval = [], [], []
            
            for Feature in df.columns[1:]:
                InputFeature = df[Feature]
                InputFeature = sm.add_constant(InputFeature)
                model = sm.Logit(Label, InputFeature).fit()
                
                Vari.append(Feature)
                Coef.append(model.params[1])
                Pval.append(model.pvalues[1])
            ```
            
            d. 데이터프레임 생성
            
            ```python
            pd.DataFrame({
                'Feature': Vari,
                'Coefficient': Coef,
                'p-value': Pval
            })
            
            Feature	Coefficient	p-value
            0	CEA_Post	0.023627	0.016328
            1	Lymphatic	0.947041	0.000057
            2	Vascular	0.856354	0.000043
            3	pStage	0.341326	0.000456
            4	pT	0.093594	0.263822
            5	pN	0.535324	0.000064
            6	Perineural	0.820546	0.011187
            7	Age	-0.000291	0.977918
            ```
            
            이렇게 데이터프레임을 만들 수 있구나, 하고 새롭게 느꼈다.
            
            e. model.params
            
            ```python
            Optimization terminated successfully.
                     Current function value: 0.423859
                     Iterations 7
            const              -15.203506
            busy_day             2.442647
            high_temperature     0.544505
            dtype: float64
            ```
            
            여기서 model.params[1] ⇒ 오른쪽만 불러오는 것.
            
            f.  model.pvalues
            
            ```python
            model.pvalues
            
            const         0.017395
            CEA_Post      0.033447
            Lymphatic     0.014498
            Vascular      0.012076
            pStage        0.545537
            pT            0.124165
            pN            0.152699
            Perineural    0.396042
            Age           0.746299
            ```
            
            g. Model = sm.Logit(Label, InputFeature).fit()
            
            ⇒ model = sm.OLS( lnodds(Label), lnodds(InputFeature)) 도 쓸 수 있다.
            
            h.  CorrlationMatrix
            
            ```python
            CorrlationMatrix = InputFeature.iloc[:, 1:].corr()
            CorrlationMatrix
            
            CEA_Post	Lymphatic	Vascular	pStage	pN	Perineural
            CEA_Post	1.000000	0.069175	0.056759	0.121155	0.165132	0.201012
            Lymphatic	0.069175	1.000000	0.228239	0.199909	0.319781	0.160543
            Vascular	0.056759	0.228239	1.000000	0.129301	0.182302	0.250198
            pStage	0.121155	0.199909	0.129301	1.000000	0.770096	0.023054
            pN	0.165132	0.319781	0.182302	0.770096	1.000000	0.055978
            Perineural	0.201012	0.160543	0.250198	0.023054	0.055978	1.000000
            ```
            
            여기서 pN과 pStage의 관계가 있다는 걸 알 수 있고, 그래서
            
            i  heatmap으로 자세히 보기
            
            ```python
            import matplotlib.pyplot as plt 
            import seaborn as sns
            
            plt.figure(figsize=(10,8))
            sns.heatmap(data = CorrlationMatrix, annot=True, fmt = '.2f', linewidths=.5, cmap='seismic')
            ```
            
            ![Untitled 2](https://user-images.githubusercontent.com/99526042/163565830-0dc988e1-6000-4266-87ec-ecdf96956d44.png)
            
            그래서 InputFeature = df[['CEA_Post', 'Lymphatic', 'Vascular', **'pStage'**, 'Perineural']] 으로
            
            추가로 넣어주게 된다.
            
            j. coef, odds, p-value
            
            ```python
            pd.DataFrame({
                'Coefficient': Model.params,
                'OddsRatio': np.exp(Model.params),
                'P-value': Model.pvalues
            })
            
            Coefficient	OddsRatio	P-value
            const	-2.159906	0.115336	0.000002
            CEA_Post	0.019506	1.019697	0.028841
            Lymphatic	0.675275	1.964573	0.007175
            Vascular	0.622445	1.863479	0.006001
            pStage	0.210626	1.234451	0.038192
            Perineural	0.330431	1.391568	0.352669
            ```
            
            k. 해당 모델을 valid.csv 파일에다가 fitting 하기
            
            ```python
            Valid = pd.read_csv('Valid.csv')
            print(Valid.head())
            
            ValidFeatures = Valid[['CEA_Post', 'Lymphatic', 'Vascular', 'pStage', 'Perineural']]
            ValidFeatures = sm.add_constant(ValidFeatures) 
            
            ValidLabel = Valid['Relapse']
            ValidPred = **Model.predict**(ValidFeatures) 
            
            from sklearn import metrics
            
            **fpr, tpr, _ = metrics.roc_curve(ValidLabel,  ValidPred)**
            **auc = metrics.roc_auc_score(ValidLabel, ValidPred)**
            plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
            plt.legend(loc=4)
            plt.show()
            ```
            
            l. fpr, tpr, _ = metrics.roc_curve(ValidLabel,  ValidPred) 이유 찾기
            
            ```python
            sklearn.metrics.roc_curve(y_true, y_score, *, 
            pos_label=None, sample_weight=None, drop_intermediate=True)
            
            일단. 
            y_true = ValidLabel # valid 파일의 재발 Relapse
            y_score = ValidPred # 이전 모델로 ValidFeatures 예측한 값
            ```
            
            여기서 fpr, tpr이 뭐냐?
            
            ```python
            Roc곡선은 **양성으로 잘못판단한 것(FPR)**에 의한 **진짜 양성의 비율 함수(TNR)**입니다. 
            **FPR은 1에서 TNR를 빼준값입니다.**  
            우선 roc 곡선을 그리기 위해선 fpr과 tpr을 구해야 합니다.
            
            출처: https://hoony-gunputer.tistory.com/entry/핸즈온-머신러닝-3강-scikitLearn-Classification를-공부하고-2편 [후니의 컴퓨터]
            ```
            
            _ 는 뭐냐? threshold. 근데 굳이 안쓰니까 이름 지정 안해준듯.
            
            앞으로 나올 다중 분류 등 참고하면 좋을 사이트
            
            [[핸즈온 머신러닝] 3강 scikitLearn Classification를 공부하고 2편](https://hoony-gunputer.tistory.com/entry/%ED%95%B8%EC%A6%88%EC%98%A8-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-3%EA%B0%95-scikitLearn-Classification%EB%A5%BC-%EA%B3%B5%EB%B6%80%ED%95%98%EA%B3%A0-2%ED%8E%B8)
